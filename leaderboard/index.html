<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=default">
    </script>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Challenge | UncharteredAI</title>
</head>

<body>

    <div class="banner">
        <img src="assets/banner.jpg" alt="Conference Template Banner">
        <div class="top-left">
            <span class="title1">Unchartered</span><span class="title2">AI</span>
        </div>
        <div class="bottom-center">
            Benchmarking Embodied Agents in Open World Environments 
            <br> NeurIPS 2025
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a title="Home Page" href=".">Home</a>
            </td>
            <td class="navigation">
                <a title="Challenge" href="challenge">Challenge</a>
            </td>
            <td class="navigation">
                <a title="Participate" href="participate">Participate</a>
            </td>
            <td class="navigation">
                <a class="current" title="Leaderboard" href="leaderboard">Leaderboard</a> 
            </td>
            <td class="navigation">
                <a title="Organizers" href="organizers">Organizers</a> 
            </td>
        </tr>
    </table>

    <h2>Leaderboard</h2>
    <p>
        The leaderboard will be updated periodically with the latest results from the challenge participants, and will be
        based on the performance indicators outlined in the Challenge section.
    </p>
    <br>
    <p>
        The leaderboard is intended for self-analysis on a set of representative scenarios that capture the kinds 
        of environments, tasks, and metrics that will be in the final test scenarios. Participants can expect the 
        leaderboard scenarios to be similar in nature to the final test scenarios, but not identical. 
    </p>
    <br>
    <p>
        The final competition rankings will be computed as the averaged task-specific metric performance on a set of 
        test scenarios which remain held-out until the final 2 weeks of the competition. In the event of a tie, 
        the ties will be broken according to the performance on General metrics. 
        Upon completion of the competition, the test scenarios will be publically released along with the winning solution.
    </p>
</body>
</html>

